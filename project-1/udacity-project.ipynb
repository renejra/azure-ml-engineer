{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "Parameter 'resource_group_name' can not be None.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rg/kc1kl6ld7_x682wfwghvtgw80000gn/T/ipykernel_26212/615323313.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Setting up the workspace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mworkspace_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'WORKSPACE_NAME'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'udacity-projects'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mws\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mWorkspace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkspace_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;31m# From a config.json file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;31m# ws = Workspace.from_config()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/azureml/core/workspace.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001B[0m\n\u001B[1;32m    594\u001B[0m             \u001B[0mauth\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInteractiveLoginAuthentication\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m         return Workspace(\n\u001B[0m\u001B[1;32m    597\u001B[0m             \u001B[0msubscription_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m             \u001B[0mresource_group\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/azureml/core/workspace.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check, _workspace_id, sku, tags, _cloud)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_disable_service_check\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 204\u001B[0;31m             auto_rest_workspace = _commands.get_workspace(\n\u001B[0m\u001B[1;32m    205\u001B[0m                 auth, subscription_id, resource_group, workspace_name, _location, _cloud, _workspace_id)\n\u001B[1;32m    206\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_workspace_autorest_object\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mauto_rest_workspace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/azureml/_project/_commands.py\u001B[0m in \u001B[0;36mget_workspace\u001B[0;34m(auth, subscription_id, resource_group_name, workspace_name, location, cloud, workspace_id)\u001B[0m\n\u001B[1;32m    434\u001B[0m     \u001B[0mAzureMachineLearningWorkspaces\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m      subscription_id).workspaces\n\u001B[0;32m--> 436\u001B[0;31m         return WorkspacesOperations.get(\n\u001B[0m\u001B[1;32m    437\u001B[0m            \u001B[0mworkspaces\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m            \u001B[0mresource_group_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/azureml/_base_sdk_common/workspace/operations/workspaces_operations.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, resource_group_name, workspace_name, custom_headers, raw, is_dataplane, **operation_config)\u001B[0m\n\u001B[1;32m     77\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubscription_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m                 'str'),\n\u001B[0;32m---> 79\u001B[0;31m             'resourceGroupName': self._serialize.url(\n\u001B[0m\u001B[1;32m     80\u001B[0m                 \u001B[0;34m\"resource_group_name\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m                 \u001B[0mresource_group_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/msrest/serialization.py\u001B[0m in \u001B[0;36murl\u001B[0;34m(self, name, data, data_type, **kwargs)\u001B[0m\n\u001B[1;32m    646\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0mraises\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mValueError\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    647\u001B[0m         \"\"\"\n\u001B[0;32m--> 648\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_http_component_validation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    649\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m             \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserialize_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/msrest/serialization.py\u001B[0m in \u001B[0;36m_http_component_validation\u001B[0;34m(self, data, data_type, name, **kwargs)\u001B[0m\n\u001B[1;32m    634\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mdata_type\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasic_types\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    635\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserialize_basic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 636\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequired\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    637\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/az-ml/lib/python3.9/site-packages/msrest/serialization.py\u001B[0m in \u001B[0;36mvalidate\u001B[0;34m(cls, data, name, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m         \u001B[0mrequired\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'required'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    729\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrequired\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 730\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValidationError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"required\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    731\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    732\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: Parameter 'resource_group_name' can not be None."
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment\n",
    "import os\n",
    "\n",
    "# Setting up the workspace\n",
    "workspace_name = os.environ.get('WORKSPACE_NAME', 'udacity-projects')\n",
    "ws = Workspace.get(name=workspace_name)\n",
    "# From a config.json file\n",
    "# ws = Workspace.from_config()\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "# Setup the experiment\n",
    "experiment_name = os.environ.get('EXPERIMENT_NAME', 'az-ml-project-1-hd')\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# Setup the environment\n",
    "# From a Conda specification file\n",
    "env = Environment.from_conda_specification(name = \"Azure-ML-Engineer\", file_path = \"az_ml_environment.yml\")\n",
    "# From a pip requirements file\n",
    "# env = Environment.from_pip_requirements(name = \"Azure-ML-Engineer\", file_path = \"path-to-pip-requirements-file\")\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rg/kc1kl6ld7_x682wfwghvtgw80000gn/T/ipykernel_23322/3813013481.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mcompute_max_nodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'CLUSTER_MAX_NODES'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mif\u001B[0m \u001B[0mcompute_name\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mws\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_targets\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mcompute_target\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mws\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_targets\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcompute_name\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcompute_target\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcompute_target\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mAmlCompute\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ws' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# Setup the compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "compute_name = os.environ.get('CLUSTER_NAME', 'cpu-cluster')\n",
    "compute_min_nodes = os.environ.get('CLUSTER_MIN_NODES', 0)\n",
    "compute_max_nodes = os.environ.get('CLUSTER_MAX_NODES', 4)\n",
    "vm_size = os.environ.get('CLUSTER_SKU', 'STANDARD_D2_V2')\n",
    "\n",
    "# Verify if the compute cluster exists\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=vm_size,\n",
    "        min_nodes=compute_min_nodes,\n",
    "        max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2610999436.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/rg/kc1kl6ld7_x682wfwghvtgw80000gn/T/ipykernel_23322/2610999436.py\"\u001B[0;36m, line \u001B[0;32m33\u001B[0m\n\u001B[0;31m    hyperdrive_config = ### YOUR CODE HERE ###\u001B[0m\n\u001B[0m                        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Setup hyperparameter tuning\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        'C': choice(0.001,0.1,1,100,1000),\n",
    "        'max_iter': uniform(100, 500)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(slack_factor=0.1, evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py and pass in the environment\n",
    "est = ScriptRunConfig(\n",
    "    source_directory=\"./scripts\",\n",
    "    script=\"train.py\",\n",
    "    compute_target=compute_target,\n",
    "    environment=env)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    run_config=est,\n",
    "    hyperparameter_sampling=ps,\n",
    "    policy=policy,\n",
    "    primary_metric_name=\"accuracy\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=100,\n",
    "    max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "hyperdrive_run = exp.submit(hyperdrive_config)\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Get best run and save the model from that run.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['accuracy'])\n",
    "print('\\n learning rate:',parameter_values[3])\n",
    "print('\\n keep probability:',parameter_values[5])\n",
    "print('\\n batch size:',parameter_values[7])\n",
    "\n",
    "model = best_run.register_model(model_name='bankmkt-hd', model_path='models/bankmkt_hd_model.joblib')\n",
    "model.download(target_dir=\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "ds = TabularDatasetFactory.from_delimited_files(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from scripts.train import clean_data\n",
    "import pandas as pd\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "\n",
    "# Since we're using AutoML, we do not need to split data now\n",
    "# Actually we will rather pass in a joined data object for AutoML\n",
    "# data_train = x.join(y)\n",
    "data_train = pd.concat([x, y], axis=1)\n",
    "data_train.to_csv('./training/data_train.csv')\n",
    "\n",
    "from azureml.core import Dataset\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='./training', target_path='./training')\n",
    "ds = TabularDatasetFactory.from_delimited_files(datastore.path(\"./training/data_train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='AUC_weighted',\n",
    "    training_data=ds.to_pandas_dataframe(),\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit automl run\n",
    "exp = Experiment(workspace=ws, name='bankmkt-automl')\n",
    "automl_run = exp.submit(automl_config, show_output=False)\n",
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save best automl model.\n",
    "best_run, model = automl_run.get_output()\n",
    "print(best_run)\n",
    "print(model)\n",
    "joblib.dump(value=best_run.id, filename=\"./models/bankmkt_automl_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}