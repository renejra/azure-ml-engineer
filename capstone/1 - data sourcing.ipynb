{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to forecast Bitcoin price movements\n",
    "# Part 1: Obtaining, exploring and preparing the data\n",
    "\n",
    "As with any other Machine Learning application, the first step is to get and prepare the data for our models.\n",
    "This notebook will focus in doing precisely this, explaining step by step the data obtained and using graphs to\n",
    " visualize these features. At the end of the notebook, we prepare clean data sets,\n",
    " which will be stored in the `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining and labelling stock market data\n",
    "\n",
    "As described in our project proposal, we will first use historical data from financial data as our data inputs.\n",
    "For this, we are going to use `yfinance` library, that scrapes this data from Yahoo Finance,\n",
    "returning it as a pandas dataframe, which will facilitate most of this work, and also we'll use `quandl`.\n",
    "\n",
    "However, since the tickers mostly have special signs and we want to create an object for each ticker historical data,\n",
    "I'll first get the data and clear the name to get an appropiate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to install quandl and an apikey for this. Only uncomment if you have it \n",
    "# %pip install yfinance quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing commonly used libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# import cufflinks as cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_values = [4,50,80]\n",
    "rsi_values = {\n",
    "    'k': 3,\n",
    "    'd': 3,\n",
    "    'alpha':14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's deal first with the ticker name, this is useful for interpretation\n",
    "\n",
    "ticker_list = [\n",
    "#             'SPY',\n",
    "           '^GSPC',\n",
    "           '^IXIC', \n",
    "           'GC=F', \n",
    "           'SI=F',\n",
    "           'CL=F', \n",
    "           '^TNX',\n",
    "           'BTC-USD',\n",
    "           '^N225',\n",
    "           '^ftse', \n",
    "           'EURUSD=X',\n",
    "           '000001.SS', \n",
    "           '^HSI',\n",
    "            ]\n",
    "\n",
    "signs = ['=','^','-','.']\n",
    "\n",
    "\n",
    "def change_name(ticker):\n",
    "    if ticker == 'tnx':\n",
    "        x = 'rates'\n",
    "    elif ticker == 'gspc':\n",
    "        x = 'spy'\n",
    "    elif ticker == 'sif':\n",
    "        x = 'silver'\n",
    "    elif ticker == 'gcf':\n",
    "        x = 'gold'\n",
    "    elif ticker == 'ixic':\n",
    "        x = 'nasdaq'\n",
    "    elif ticker == 'clf':\n",
    "        x = 'crude oil'\n",
    "    elif ticker == 'btcusd':\n",
    "        x = 'btc'\n",
    "    elif ticker == 'n225':\n",
    "        x = 'nikkei'\n",
    "    elif ticker == 'eurusdx':\n",
    "        x = 'euro'\n",
    "    elif ticker == '000001ss':\n",
    "        x = 'shangai'\n",
    "    else:\n",
    "        x = ticker\n",
    "    return x\n",
    "\n",
    "def lower_clean_name(word, signs):\n",
    "    word = word.lower()\n",
    "    for char in signs: \n",
    "        word = word.replace(char, '')\n",
    "    return word\n",
    "\n",
    "# test change labels amongst indices\n",
    "\n",
    "labels = [lower_clean_name(word,signs) for word in ticker_list]\n",
    "changed_labels = [change_name(x) for x in labels]\n",
    "\n",
    "for x in range(len(labels)):\n",
    "    print(labels[x] +' = '+changed_labels[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ticker_concat = \" \".join(ticker_list)\n",
    "ohlcv = yf.download(ticker_concat, start=\"2008-01-01\", threads=False)\n",
    "tickers = yf.download(ticker_concat, start=\"2008-01-01\", group_by='tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns to changed labels\n",
    "for x in [ohlcv, tickers]:\n",
    "    x.rename(columns = lambda x: change_name(lower_clean_name(x,signs)), inplace=True)\n",
    "    x[x.index.min():]\n",
    "\n",
    "# ohlcv.rename(columns = lambda x: change_name(lower_clean_name(x,signs)), inplace=True)\n",
    "# tickers.rename(columns = lambda x: change_name(lower_clean_name(x,signs)), inplace=True)\n",
    "# ohlcv[ohlcv.index.min():]\n",
    "# tickers[ohlcv.index.min():]\n",
    "\n",
    "open = ohlcv['open'].fillna(method='ffill')\n",
    "high = ohlcv['high'].fillna(method='ffill')\n",
    "low = ohlcv['low'].fillna(method='ffill')\n",
    "close = ohlcv['close'].fillna(method='ffill')\n",
    "volume = ohlcv['volume'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns and cumulative returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make stock prices comparable, we first need to bring all of them into the same base.\n",
    "For this, we will use the `daily returns` of holding this stock. This way, instead of comparing stocks\n",
    "with different prices (for example, Nikkei starting at 10k USD vs FTSE at 5k USD) we will bring all of them\n",
    " to the base of one at the start of the timeframe and record their daily increase or decrease in % to that base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = close[close.btc.notnull()]\n",
    "returns = close.pct_change(1)\n",
    "cumulative = (1 + returns).cumprod()\n",
    "\n",
    "close.plot(figsize=(12,6),label='Price', title='Price [$]')\n",
    "close.plot(figsize=(12,6),label='Price (log scale)', logy=True, title='Log Price [$]')\n",
    "cumulative.plot(figsize=(12,6),label='Cumulative Returns', title='Returns [$]')\n",
    "cumulative.plot(figsize=(12,6),label='Cumulative Returns (log)', logy=True, title='Log Returns [$]')\n",
    "cumulative.loc[:,cumulative.columns != 'btc'].plot(\n",
    "    figsize=(12,6), label='Cumulative Returns', title='Returns, excluding BTC [$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even by using returns as the base metric, we can see that we needed to plot them in a logarithmic scale,\n",
    "for their changes to be made comparable with Bitcoin, given the astonishing returns on the asset since 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing technical analysis calculations\n",
    "\n",
    "Now we will calculate several indicators typically used in technical analysis of stock prices,\n",
    "such as simple moving averages, the (stochastic) relative strength index and other statistical measures s.a.\n",
    "the expanding standard deviation of Bitcoin price.\n",
    "\n",
    "### Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ma(data, ma1=4, ma2=96, ma3=200):\n",
    "    data['MA'+str(ma1)] = round(data['close'].rolling(ma1).mean(),0)\n",
    "    data['MA'+str(ma2)] = round(data['close'].rolling(ma2).mean(),0)\n",
    "    data['MA'+str(ma3)] = round(data['close'].rolling(ma3).mean(),0)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Stochastic) Relative Strenght Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_rsi(data, alpha=14, smoothK=3, smoothD=3):\n",
    "    \n",
    "    data['change'] = data['close'].pct_change(1)\n",
    "    data['cum_change'] = (data['change']+1).cumprod()\n",
    "    data['k'] = 0\n",
    "    data['d'] = 0\n",
    "\n",
    "    cond_k = data.change > 0\n",
    "    cond_d = data.change < 0\n",
    "\n",
    "    data['k'] = data.k.mask(cond_k, data['change'])\n",
    "    data['d'] = data.d.mask(cond_d, - data['change'])\n",
    "    # data['num'] = data['k'].rolling(alpha).mean()\n",
    "    \n",
    "    data['num'] = pd.Series.ewm(data['k'], span=alpha).mean()\n",
    "    data['div'] = pd.Series.ewm(data['d'], span=alpha).mean()\n",
    "    \n",
    "    # data['div'] = data['d'].rolling(alpha).mean()\n",
    "    data['rs'] = data['num']/data['div']\n",
    "    data['RSI'] = (100 - (100/(1+data['rs'])))\n",
    "    data['RSImin'] = data['RSI'].rolling(alpha).min()\n",
    "    data['RSImax'] = data['RSI'].rolling(alpha).max()\n",
    "    data['stochRSI'] = 100*(data['RSI'] - data['RSImin']) / (data['RSImax'] - data['RSImin'])\n",
    "    data['smoothK'] = round(data['stochRSI'].rolling(smoothK).mean(),2)\n",
    "    data['smoothD'] = round(data['smoothK'].rolling(smoothD).mean(),2)\n",
    "    data['K1'] = data['smoothK'].shift(1)\n",
    "    data['D1'] = data['smoothD'].shift(1)\n",
    "\n",
    "    # cond_num_zero = data.num == 0\n",
    "    # data['RSI'] = data.RSI.mask(cond_num_zero, 0)\n",
    "\n",
    "    # cond_div_zero = data.div == 0\n",
    "    # data['RSI'] = data.RSI.mask(cond_div_zero, 100)\n",
    "\n",
    "    return data\n",
    "\n",
    "def transform_std(df, confidence=80):\n",
    "    df['btc_std_dev'] = df['change'].expanding(2).std()\n",
    "    df['btc_mean'] = df['change'].expanding(2).mean()\n",
    "    # df['conf_int_p'] = np.percentile(df['change'], (100-confidence)/2)\n",
    "    # df['conf_int_m'] = np.percentile(df['change'], confidence + (100-confidence)/2)\n",
    "    df['std_dif'] = (df['close'] - df['btc_std_dev']).abs()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Here we start doing technical indicators for our target instrument\n",
    "\n",
    "# btc = yf.Ticker('BTC-USD')\n",
    "# btc = btc.history(start=\"2008-01-01\")\n",
    "\n",
    "btc = tickers.btc\n",
    "# btc = tickers['BTCUSD=X']\n",
    "\n",
    "# btc.drop(columns=['Dividends', 'Stock Splits'], inplace=True)\n",
    "# btc = btc[btc.ohlcv.notnull()]\n",
    "\n",
    "btc = transform_std(transform_rsi(transform_ma(btc, ma_values[0], ma_values[1], ma_values[2])))\n",
    "btc.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at volume figures to see if it makes sense to add to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume.plot(logy=True, figsize=(20,6))\n",
    "v_returns = volume.pct_change(1)\n",
    "v_cumulative = (1+v_returns).cumprod()\n",
    "v_cumulative.plot(logy=True, figsize=(20,6), title=\"Cumulative Log Volume Traded\")\n",
    "v_returns.hist(bins=100, figsize=(30,30), range=[-5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will include some of these later, but we'll need to drop a couple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.drop(columns=['rates', 'euro'], inplace=True)\n",
    "volume.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc[['high','low','close','std_dif']].plot(figsize=(14,6),logy=True, title='Bitcoin Price')\n",
    "btc[5:]['btc_std_dev'].plot(figsize=(14,6), title='Standard deviation of daily change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of technical indicators to feed the model\n",
    "btc = btc[[f'MA{ma_values[0]}',f'MA{ma_values[1]}', f'MA{ma_values[2]}', 'stochRSI', 'RSI','btc_std_dev','std_dif']].\\\\\n",
    "    fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.rename(columns = lambda x: \"vol_\" + x, inplace=True)\n",
    "data = pd.concat([cumulative, btc], axis=1)\n",
    "data = pd.concat([data, volume], axis=1)\n",
    "\n",
    "\n",
    "# data.drop(data.index[0], inplace=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting fundamental Bitcoin data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental Bitcoin's blockchain data will also be included, such as hashrate, mining difficulty,\n",
    "(daily) number of transactions and cost per transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import os\n",
    "\n",
    "# from settings import QUANDLKEY\n",
    "quandl_key = os.getenv(\"QUANDLKEY\")\n",
    "quandl.ApiConfig.api_key = quandl_key # (insert if available, else there is a ratelimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quandl_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# btc mining is an interesting source, but free data has not the same quality ;)\n",
    "# btcmining = quandl.get('BITCOINWATCH/MINING') # total btc and marketcap, bad quality data\n",
    "# btcmining.fillna(method='ffill').plot(legend=None, logy=True)\n",
    "\n",
    "btc_hrate = quandl.get('BCHAIN/HRATE') # hashrate\n",
    "btc_diff = quandl.get('BCHAIN/DIFF') # difficulty\n",
    "btc_ntrat = quandl.get('BCHAIN/NTRAT') # number of transactions\n",
    "btc_cptra = quandl.get('BCHAIN/CPTRA') # cost per transaction\n",
    "m2 = quandl.get(\"FED/M2_N_WM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = pd.concat([btc_hrate, btc_diff, btc_ntrat, btc_cptra], axis=1) #, m2]\n",
    "# fundamentals.fillna(method='bfill')\n",
    "fundamentals.columns = ['hashrate','difficulty','transactions','t_cost'] #, 'm2']\n",
    "fundamentals.plot(figsize=(12,12), logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_date = '2014-09-22'\n",
    "compare_date = '2020-01-21'\n",
    "\n",
    "(1 + m2[compare_date:].pct_change()).cumprod().plot(logy=True)\n",
    "(1 + returns.btc[compare_date:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data,fundamentals], axis=1)\n",
    "df = df[df.btc.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing functions for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure that no feature becomes more important in the dataset than the others,\n",
    "we will create functions to normalize these and bring them back to the dataset's original state.\n",
    "This will be used later before saving the feed-in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(df, log=False):\n",
    "    if log:\n",
    "        df = np.log(df)\n",
    "    normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "    return normalized_df, df.min(), df.max()\n",
    "\n",
    "def back_min_max(ndf,mindf,maxdf, log=False):\n",
    "    df = ndf*(maxdf-mindf) + mindf\n",
    "    if log:\n",
    "        df = np.exp(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizer(df, log=False):\n",
    "    '''\n",
    "    Returns log normalized and standartized df, mean and standard deviation of raw dataframe\n",
    "    '''\n",
    "    if log:\n",
    "        df = np.log(df)\n",
    "    ndf = (df-df.mean())/df.std()\n",
    "\n",
    "    return ndf, df.mean(), df.std()\n",
    "\n",
    "def back_standardizer(ndf, mean, std, log=False):\n",
    "    df = ndf*std + mean\n",
    "    if log:\n",
    "        df = np.exp(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling buy, sell and no-trade signals\n",
    "\n",
    "Following our end-goal, we will need to predict whether prices are going to go up or down.\n",
    "For this, the condition for the labels will be that if price goes up by more than a certain confidence level it's a buy,\n",
    " down a certain confidence level or less a sell, and values in between labelled as no-trade zone.\n",
    "\n",
    "We will need to shift by one this values to become the predicted labels of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.btc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the confidence intervals above, I will take the top 75% interval +2.3% as buy label (1),\n",
    "-1.36% for the sell label (2), and the values in between as no-trade (0).\n",
    "The objective of the classification problem will be to **predict the next day's label to give a trading signal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "plt.hist(returns.btc, bins=200 , range=(-0.4, 0.6), label='Distribution of Bitcoin daily returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "plt.hist(cumulative.btc, bins=200, label='Distribution of Bitcoin daily returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logy = np.log(cumulative.btc)\n",
    "logy.hist(bins=200, figsize=(14,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['shangai', 'btc', 'oil', 'euro', 'gold', 'silver', 'ftse', 'spy',\n",
    "       'hsi', 'nasdaq', 'nikkei', 'rates']:\n",
    "    try:\n",
    "        exec(f'np.log(cumulative.{x}).plot(figsize=(20,10))')\n",
    "    except Exception:\n",
    "        print('shit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(returns.btc)\n",
    "labels['returns'] = returns.btc\n",
    "labels = pd.concat([labels.returns, close.btc[close.btc.notnull()]], axis =1)\n",
    "labels.rename(columns={'btc':'btc_close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cond = labels.returns > 0.022985 # returns.btc.describe()['75%']\n",
    "sell_cond = labels.returns < -0.013636 # returns.btc.describe()['25%']\n",
    "\n",
    "labels['c_label'] = 0\n",
    "labels['c_label'] = labels['c_label'].mask(buy_cond, 1)\n",
    "labels['c_label'] = labels['c_label'].mask(sell_cond, -1)\n",
    "\n",
    "\n",
    "# Backtesting, used for later\n",
    "\n",
    "labels['bkt_returns'] = 0\n",
    "labels['bkt_returns'] = labels['bkt_returns'].mask(buy_cond, labels.returns)\n",
    "labels['bkt_returns'] = labels['bkt_returns'].mask(sell_cond, labels.returns)\n",
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row data cleaning\n",
    "df.describe().loc['count'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "I'll consider the minimal available records as starting point and select the training data.\n",
    "Dates afterwards will be test data. We will also get rid of NA values that aren't useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,labels], axis=1)\n",
    "df.rename(columns={'btc':'btc_cumulative'}, inplace=True)\n",
    "\n",
    "df = df[-int(df.describe().loc['count'].min()):]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['returns_label'] = df['c_label']\n",
    "df['c_label'] = df['c_label'].shift(-1)\n",
    "df['r_label'] = df['btc_close'].shift(-1)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization step\n",
    "### Pick your poison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndf, mindf, maxdf = min_max_scaler(df, log=False)\n",
    "\n",
    "ndf, mean, std = standardizer(df, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between all features and labels used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation of BTC with features\n",
    "\n",
    "cor_list = df.corr()['btc_cumulative'].sort_values(ascending=False).round(2)\n",
    "cor_list.drop(index=['btc_cumulative', 'btc_close', 'std_dif', 'MA4', 'r_label', 'MA96', 't_cost',\n",
    "    'MA200', 'transactions', 'btc_std_dev',\n",
    "    'RSI', 'bkt_returns', 'returns', 'stochRSI',\n",
    "    'returns_label', 'c_label', 'difficulty', 'hashrate' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalized correlation does not change, uncomment below to see\n",
    "\n",
    "ndf.corr().btc_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(df.corr(), \n",
    "        xticklabels=df.corr().columns,\n",
    "        yticklabels=df.corr().columns, ax=ax,\n",
    "            annot=True, \n",
    "            cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of normalized features\n",
    "print(ndf.shape)\n",
    "ndf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take as training data from beginning of time until 2018, and test data from 2018-01-01 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.btc_close.loc[:].plot(figsize=(12,8), logy=True, title='BTC price (log scale)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df.loc[:'2018-01-01']\n",
    "train_nx = ndf.loc[:'2018-01-01']\n",
    "\n",
    "test_x = df.loc['2018-01-01':]\n",
    "test_nx = ndf.loc['2018-01-01':]\n",
    "\n",
    "# Dropping last column of test (since they are shifted)\n",
    "test_x.drop(test_x.index[-1], inplace=True)\n",
    "test_nx.drop(test_nx.index[-1], inplace=True)\n",
    "\n",
    "# Create labels for regression (price forecast) and classification (trading prediction)\n",
    "train_y = train_x[['r_label', 'c_label']]\n",
    "train_ny = train_nx[['r_label', 'c_label']]\n",
    "\n",
    "test_y = test_x[['r_label', 'c_label']]\n",
    "test_ny = test_nx[['r_label', 'c_label']]\n",
    "\n",
    "test_x.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop labels and unneeded columns on train & test feature data sets\n",
    "drop_list = ['r_label','c_label','bkt_returns']\n",
    "drop_df = [train_x, train_nx, test_x, test_nx]\n",
    "\n",
    "for x in drop_df:\n",
    "    x.drop(columns=drop_list, inplace=True)\n",
    "#     x['ts'] = x['Date'].datetime.astype('int64') // 10**9\n",
    "#     x.set_index('ts')\n",
    "#     x.drop(columns=['ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing original and normalized data in CSVs\n",
    "store_list = [train_x, train_nx, test_x, test_nx, train_y, train_ny, test_y, test_ny]\n",
    "# !mkdir data\n",
    "store_name = ['data/train_x.csv', 'data/train_nx.csv', 'data/test_x.csv', 'data/test_nx.csv', 'data/train_y.csv', 'data/train_ny.csv', 'data/test_y.csv', 'data/test_ny.csv']\n",
    "\n",
    "for i in range(len(store_list)):\n",
    "    store_list[i].to_csv(store_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap and Discussion\n",
    "\n",
    "### What was done?\n",
    "\n",
    "We started by obtaining and preprocessing the data, specifically:\n",
    "- Used Quandl and yfinance to source stock market, currencies and Bitcoin fundamentals. \n",
    "- Calculated technical analysis indicators, such as simple moving averages, relative strength index (RSI),\n",
    "- stochastic RSI, cumulated standard deviation and distance to prices.\n",
    "- Labelled data necessary to provide trading signal predictions later. These labels were selected according to the\n",
    "- historical distribution of daily Bitcoin returns.\n",
    "- Created a heatmap to have an initial feeling of correlation between features.\n",
    "- Cleaned up the data sets for NA values and stored training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What comes next?\n",
    "\n",
    "In the next notebook, you will find the following sections:\n",
    "\n",
    "- **Splitting the data** into test, train and labels\n",
    "- **PCA for dimensionality reduction** / feature selection\n",
    "- **XGBoost for price forecasting and trading signal**\n",
    "- **Neural network for price forecasting and trading signal**\n",
    "- **Final discussion and model comparisson**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cc4842860dd895609e41a125ca96f8f38382bb08a3a4363bcdb74f1671a714"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('finance': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}