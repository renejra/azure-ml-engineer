{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "Detailed package dependencies can be found on the [`env.yml`](envs/env.yml).\n",
        "Use `conda install --file envs/env.yml` on your Terminal.\n",
        "This file can be used to reproduce the conda environment used in this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import os\n",
        "import requests"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046960065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Setting up the workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Registering and building the environment (not needed in AutoML)\n",
        "env = Environment.from_conda_specification(name = \"az-capstone\", file_path = \"envs/env.yml\")\n",
        "env = env.register(workspace=ws)\n",
        "env_build = env.build(workspace=ws)\n",
        "\n",
        "# Setup the experiment\n",
        "exp_name = 'az-capstone-automl'\n",
        "exp=Experiment(ws, exp_name)\n",
        "\n",
        "# Enable logs\n",
        "run = exp.start_logging()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046977158
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now deploy the necessary Compute Cluster, or check if there is already an existing one we can use."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the compute cluster\n",
        "compute_name = os.environ.get('CLUSTER_NAME', 'automl-cluster')\n",
        "compute_min_nodes = os.environ.get('CLUSTER_MIN_NODES', 0)\n",
        "compute_max_nodes = os.environ.get('CLUSTER_MAX_NODES', 4)\n",
        "vm_size = os.environ.get('CLUSTER_SKU', 'STANDARD_D2_V2')\n",
        "\n",
        "# Verify if the compute cluster exists\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size=vm_size,\n",
        "        min_nodes=compute_min_nodes,\n",
        "        max_nodes=compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "\n",
        "    # poll for a minimum number of nodes and for a specific timeout.\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found compute target. just use it. automl-cluster\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046977538
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "The dataset we are using will be the one resulting from the [previous notebook](1-data-sourcing.ipynb) where\n",
        "we dug into data sourcing and did some processing prior this task. The dataset\n",
        "consists on financial data including OHLCV (open, high, low, close, volume) from diverse instruments (indices,\n",
        "commodities, interest rates...) and technical indicators (moving averages, RSI, standard deviation...), that we will\n",
        "use to create a ML-based trading model, that gives BUY, HOLD or SELL signals for Bitcoin trading.\n",
        "\n",
        "If you want to dig more into how the dataset looks like or\n",
        "into how the above-mentioned signals are generated, please refer to the \"labelling the data\" section of\n",
        "the [data sourcing notebook](1-data-sourcing.ipynb) or the latest  print view of the DataFrame's head and/or tail\n",
        "provided on the same file.\n",
        "\n",
        "The task we will be trying to solve is basically a **classification problem**.\n",
        "We are to predict whether the next-day, Bitcoin returns will be on the top 25% most positive returns (BUY, 1),\n",
        "the 25% most negative (SELL, -1), or somewhere in between (HOLD, 0).\n",
        "\n",
        "Since AutoML does grid search over features and normalization procedures, we will take joint, unaltered data as feed\n",
        "in to the model. What we will make is dropping the last features and labels that are not really needed for the task."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the data and drop unneeded columns for AutoML exercise\n",
        "df = pd.read_csv('data/df.csv')\n",
        "print('dataset shape: ', df.shape)\n",
        "print('columns:\\n', df.columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "dataset shape:  (2703, 34)\ncolumns:\n Index(['Date', 'shangai', 'btc', 'crude oil', 'euro', 'gold', 'silver', 'ftse',\n       'spy', 'hsi', 'nasdaq', 'nikkei', 'rates', 'open', 'high', 'low', 'MA4',\n       'MA50', 'MA80', 'stochRSI', 'RSI', 'btc_std_dev', 'std_dif', 'vol_btc',\n       'hashrate', 'difficulty', 'transactions', 't_cost', 'y_returns',\n       'y_close', 'y_c', 'y_returns_shift', 'y_c_shift', 'y_close_shift'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046977678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col_list = ['y_close', 'y_c', 'y_close_shift', 'y_returns_shift']\n",
        "df.drop(columns=drop_col_list, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046977778
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the dataset\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(df, datastore, \"automl_dataset\", show_progress=True)\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/e3c7a317-8d12-40dc-b675-c579edb6ff6d/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046982573
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "Our AutoML run will have the classification task of predicting next day's buy, sell or hold label, or the column\n",
        "`y_c_weighted`. Our primary metric will be AUC weighted, to deal with the instability on price dataset.\n",
        " I'm also adding the automatic featurization, so\n",
        "AutoML takes care of necessary data transformations, trying out different methods.\n",
        "\n",
        "As timeout for this project I will use 30 minutes. The usage of VMs to access Azure on a limited time (1h) adds pressure\n",
        "on this metric. We also need time to analize results afterwards, so air time using the VM is important."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\"featurization\": 'auto'}"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1645046982670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters for AutoMLConfig\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task='classification',\n",
        "    primary_metric='accuracy',\n",
        "    training_data=df,\n",
        "    label_column_name='y_c_shift',\n",
        "    n_cross_validations=5,\n",
        "    **automl_settings)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645046982764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the experiment run\n",
        "automl_run = exp.submit(automl_config, show_output=False)\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationException",
          "evalue": "ValidationException:\n\tMessage: Install the required versions of packages using the requirements file. Requirements file location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/validated_linux_requirements.txt. Alternatively, use remote target to avoid dependency management. \nPackage name/Required version/Installed version\nazureml-interpret/numpy<=1.20.*/numpy 1.22.2\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Install the required versions of packages using the requirements file. Requirements file location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/validated_linux_requirements.txt. Alternatively, use remote target to avoid dependency management. \\nPackage name/Required version/Installed version\\nazureml-interpret/numpy<=1.20.*/numpy 1.22.2\",\n        \"target\": \"azureml-interpret\",\n        \"inner_error\": {\n            \"code\": \"NotSupported\",\n            \"inner_error\": {\n                \"code\": \"IncompatibleOrMissingDependency\"\n            }\n        },\n        \"reference_code\": \"435ab938-fd87-49bc-932e-6eec0d6aee4f\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Submit the experiment run\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m automl_run \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoml_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m automl_run\u001b[38;5;241m.\u001b[39mwait_for_completion(show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/experiment.py:220\u001b[0m, in \u001b[0;36mExperiment.submit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m submit_func \u001b[38;5;241m=\u001b[39m get_experiment_submit(config)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit config \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)):\n\u001b[0;32m--> 220\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43msubmit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags(tags)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:96\u001b[0m, in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m settings \u001b[38;5;241m=\u001b[39m _azureautomlsettings\u001b[38;5;241m.\u001b[39mAzureAutoMLSettings(experiment\u001b[38;5;241m=\u001b[39mexperiment, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_server\u001b[38;5;241m.\u001b[39mnew_log_context(parent_run_id\u001b[38;5;241m=\u001b[39mparent_run_id):\n\u001b[0;32m---> 96\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m \u001b[43m_start_execution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     automl_run\u001b[38;5;241m.\u001b[39madd_properties(global_tracking_info_registry\u001b[38;5;241m.\u001b[39mgather_all(settings\u001b[38;5;241m.\u001b[39mpath))\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m automl_run\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:211\u001b[0m, in \u001b[0;36m_start_execution\u001b[0;34m(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)\u001b[0m\n\u001b[1;32m    209\u001b[0m     _disable_mlflow(settings_obj)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings_obj\u001b[38;5;241m.\u001b[39m_ignore_package_version_incompatibilities:\n\u001b[0;32m--> 211\u001b[0m         \u001b[43mpackage_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_package_incompatibilities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpackages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOML_PACKAGES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignored_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_PACKAGES_TO_IGNORE_VERSIONS\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m _default_execution(experiment, settings_obj, fit_params, \u001b[38;5;28;01mTrue\u001b[39;00m, show_output, parent_run_id)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_managed:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/package_utilities.py:424\u001b[0m, in \u001b[0;36m_get_package_incompatibilities\u001b[0;34m(packages, ignored_dependencies, is_databricks_run)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationException\u001b[38;5;241m.\u001b[39m_with_error(\n\u001b[1;32m    415\u001b[0m             AzureMLError\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    416\u001b[0m                 IncompatibleOrMissingDependencyDatabricks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m             )\n\u001b[1;32m    422\u001b[0m         )\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationException\u001b[38;5;241m.\u001b[39m_with_error(\n\u001b[1;32m    425\u001b[0m             AzureMLError\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    426\u001b[0m                 IncompatibleOrMissingDependency,\n\u001b[1;32m    427\u001b[0m                 target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(incompatible_packages\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[1;32m    428\u001b[0m                 missing_packages_message_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPackage name/Required version/Installed version\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    429\u001b[0m                 missing_packages_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(messages),\n\u001b[1;32m    430\u001b[0m                 reference_code\u001b[38;5;241m=\u001b[39mReferenceCodes\u001b[38;5;241m.\u001b[39m_PACKAGE_INCOMPATIBILITIES_FOUND,\n\u001b[1;32m    431\u001b[0m                 validated_requirements_file_path\u001b[38;5;241m=\u001b[39mVALIDATED_REQ_FILE_PATH\n\u001b[1;32m    432\u001b[0m             )\n\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    435\u001b[0m validated_requirements \u001b[38;5;241m=\u001b[39m _get_validated_requirements()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validated_requirements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mValidationException\u001b[0m: ValidationException:\n\tMessage: Install the required versions of packages using the requirements file. Requirements file location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/validated_linux_requirements.txt. Alternatively, use remote target to avoid dependency management. \nPackage name/Required version/Installed version\nazureml-interpret/numpy<=1.20.*/numpy 1.22.2\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Install the required versions of packages using the requirements file. Requirements file location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/validated_linux_requirements.txt. Alternatively, use remote target to avoid dependency management. \\nPackage name/Required version/Installed version\\nazureml-interpret/numpy<=1.20.*/numpy 1.22.2\",\n        \"target\": \"azureml-interpret\",\n        \"inner_error\": {\n            \"code\": \"NotSupported\",\n            \"inner_error\": {\n                \"code\": \"IncompatibleOrMissingDependency\"\n            }\n        },\n        \"reference_code\": \"435ab938-fd87-49bc-932e-6eec0d6aee4f\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1644782458979
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "By using the RunDetails widget, we can appreciate different experiments metrics.\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance.\n",
        "Why do you think some models did better than others?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(automl_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644782459118
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save best model\n",
        "best_run, model = automl_run.get_output()\n",
        "print(best_run, '\\n')\n",
        "print(model)\n",
        "joblib.dump(value=best_run.id, filename=\"./models/bitcoin-automl.joblib\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644782460190
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models.\n",
        "Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'best-automl-model'\n",
        "description = \"AutoML model for predicting day-ahead Bitcoin price movements\"\n",
        "tags = None\n",
        "model = automl_run.register_model(model_name=model_name, description=description, tags=tags)\n",
        "print(automl_run.model_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461350
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461559
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "best_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", \"inference/score_demo.py\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644784811730
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_file_name = \"./inference/score.py\"\n",
        "inference_config = InferenceConfig(environment=env, entry_script=script_file_name)\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=2,\n",
        "    memory_gb=2,\n",
        "    tags={\"area\": \"Trading\", \"type\": \"automl_classification\"},\n",
        "    description=\"service for Bitcoin trading signals\"\n",
        ")\n",
        "\n",
        "aci_service_name = model_name.lower()\n",
        "print(aci_service_name)\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)\n",
        "\n",
        "aci_service.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "X_test_json = df.tail().to_json(orient=\"records\")\n",
        "data = '{\"data\": ' + X_test_json + \"}\"\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
        "\n",
        "y_pred = json.loads(json.loads(resp.text))[\"result\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deletion of endpoints and resources"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the inference compute instance\n",
        "# aci_service.delete()\n",
        "\n",
        "# Deleting compute cluster\n",
        "compute_target.delete()\n",
        "# print('Compute cluster deleted!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645045473875
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}