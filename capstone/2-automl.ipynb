{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Automated ML\n",
    "\n",
    "Detailed package dependencies can be found on the [`env.yml`](envs/env.yml).\n",
    "Use `conda install --file envs/env.yml` on your Terminal.\n",
    "This file can be used to reproduce the conda environment used in this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Setting up the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Registering and building the environment\n",
    "env = Environment.from_conda_specification(name = \"az-ml-pers\", file_path = \"envs/env.yml\")\n",
    "env = env.register(workspace=ws)\n",
    "env_build = env.build(workspace=ws)\n",
    "\n",
    "# Setup the experiment\n",
    "experiment_name = 'udacity-capstone'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "# Enable logs\n",
    "run = exp.start_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset we are using will be the one resulting from the [previous notebook](1-data-sourcing.ipynb) where\n",
    "we dug into data sourcing and did some processing prior this task. The dataset\n",
    "consists on financial data including OHLCV (open, high, low, close, volume) from diverse instruments (indices,\n",
    "commodities, interest rates...) and technical indicators (moving averages, RSI, standard deviation...), that we will\n",
    "use to create a ML-based trading model, that gives BUY, HOLD or SELL signals for Bitcoin trading.\n",
    "\n",
    "If you want to dig more into how the dataset looks like or\n",
    "into how the above-mentioned signals are generated, please refer to the \"labelling the data\" section of\n",
    "the [data sourcing notebook](1-data-sourcing.ipynb) or the latest  print view of the DataFrame's head and/or tail\n",
    "provided on the same file.\n",
    "\n",
    "The task we will be trying to solve is basically a **classification problem**.\n",
    "We are to predict whether the next-day, Bitcoin returns will be on the top 25% most positive returns (BUY, 1),\n",
    "the 25% most negative (SELL, -1), or somewhere in between (HOLD, 0).\n",
    "\n",
    "Since AutoML does grid search over features and normalization procedures, we will take joint, unaltered data as feed\n",
    "in to the model. What we will make is dropping the last features and labels that are not really needed for the task."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Access the data and drop unneeded columns for AutoML exercise\n",
    "df = pd.read_csv('data/df.csv')\n",
    "drop_col_list = ['', '']\n",
    "df.drop(columns=drop_col_list, inplace=True)\n",
    "\n",
    "# Register the dataset\n",
    "datastore = ws.get_default_datastore()\n",
    "dataset = Dataset.Tabular.register_pandas_dataframe(df, datastore, \"automl_dataset\", show_progress=True)\n",
    "df = dataset.to_pandas_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and configuration you used below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO: Save the best model"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}