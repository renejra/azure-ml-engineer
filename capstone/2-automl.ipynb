{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "Detailed package dependencies can be found on the [`env.yml`](envs/env.yml).\n",
        "Use `conda install --file envs/env.yml` on your Terminal.\n",
        "This file can be used to reproduce the conda environment used in this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import os\n",
        "import requests"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052284850
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Setting up the workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Registering and building the environment (not needed in AutoML)\n",
        "env = Environment.from_conda_specification(name = \"azcapstone\", file_path = \"env.yml\")\n",
        "env = env.register(workspace=ws)\n",
        "env_build = env.build(workspace=ws)\n",
        "\n",
        "# Setup the experiment\n",
        "exp_name = 'az-capstone-automl'\n",
        "exp=Experiment(ws, exp_name)\n",
        "\n",
        "# Enable logs\n",
        "run = exp.start_logging()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052292258
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now deploy the necessary Compute Cluster, or check if there is already an existing one we can use."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the compute cluster\n",
        "compute_name = os.environ.get('CLUSTER_NAME', 'automl-cluster')\n",
        "compute_min_nodes = os.environ.get('CLUSTER_MIN_NODES', 0)\n",
        "compute_max_nodes = os.environ.get('CLUSTER_MAX_NODES', 4)\n",
        "vm_size = os.environ.get('CLUSTER_SKU', 'STANDARD_D2_V2')\n",
        "\n",
        "# Verify if the compute cluster exists\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size=vm_size,\n",
        "        min_nodes=compute_min_nodes,\n",
        "        max_nodes=compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "\n",
        "    # poll for a minimum number of nodes and for a specific timeout.\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found compute target. just use it. automl-cluster\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052292800
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "The dataset we are using will be the one resulting from the [previous notebook](1-data-sourcing.ipynb) where\n",
        "we dug into data sourcing and did some processing prior this task. The dataset\n",
        "consists on financial data including OHLCV (open, high, low, close, volume) from diverse instruments (indices,\n",
        "commodities, interest rates...) and technical indicators (moving averages, RSI, standard deviation...), that we will\n",
        "use to create a ML-based trading model, that gives BUY, HOLD or SELL signals for Bitcoin trading.\n",
        "\n",
        "If you want to dig more into how the dataset looks like or\n",
        "into how the above-mentioned signals are generated, please refer to the \"labelling the data\" section of\n",
        "the [data sourcing notebook](1-data-sourcing.ipynb) or the latest  print view of the DataFrame's head and/or tail\n",
        "provided on the same file.\n",
        "\n",
        "The task we will be trying to solve is basically a **classification problem**.\n",
        "We are to predict whether the next-day, Bitcoin returns will be on the top 25% most positive returns (BUY, 1),\n",
        "the 25% most negative (SELL, -1), or somewhere in between (HOLD, 0).\n",
        "\n",
        "Since AutoML does grid search over features and normalization procedures, we will take joint, unaltered data as feed\n",
        "in to the model. What we will make is dropping the last features and labels that are not really needed for the task."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the data and drop unneeded columns for AutoML exercise\n",
        "df = pd.read_csv('data/df.csv')\n",
        "print('dataset shape: ', df.shape)\n",
        "print('columns:\\n', df.columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "dataset shape:  (2703, 34)\ncolumns:\n Index(['Date', 'shangai', 'btc', 'crude oil', 'euro', 'gold', 'silver', 'ftse',\n       'spy', 'hsi', 'nasdaq', 'nikkei', 'rates', 'open', 'high', 'low', 'MA4',\n       'MA50', 'MA80', 'stochRSI', 'RSI', 'btc_std_dev', 'std_dif', 'vol_btc',\n       'hashrate', 'difficulty', 'transactions', 't_cost', 'y_returns',\n       'y_close', 'y_c', 'y_returns_shift', 'y_c_shift', 'y_close_shift'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052293005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col_list = ['y_close', 'y_c', 'y_close_shift', 'y_returns_shift']\n",
        "df.drop(columns=drop_col_list, inplace=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052293207
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the dataset\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(df, datastore, \"automl_dataset\", show_progress=True)\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/e425ebec-4316-4bb2-aed9-187a1e6c2c97/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052298024
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "Our AutoML run will have the classification task of predicting next day's buy, sell or hold label, or the column\n",
        "`y_c_weighted`. Our primary metric will be AUC weighted, to deal with the instability on price dataset.\n",
        " I'm also adding the automatic featurization, so\n",
        "AutoML takes care of necessary data transformations, trying out different methods.\n",
        "\n",
        "As timeout for this project I will use 30 minutes. The usage of VMs to access Azure on a limited time (1h) adds pressure\n",
        "on this metric. We also need time to analize results afterwards, so air time using the VM is important."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\"featurization\": 'auto'}"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1645052298345
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters for AutoMLConfig\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task='classification',\n",
        "    primary_metric='accuracy',\n",
        "    training_data=df,\n",
        "    label_column_name='y_c_shift',\n",
        "    n_cross_validations=5,\n",
        "    **automl_settings)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645052298539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the experiment run\n",
        "automl_run = exp.submit(automl_config, show_output=True)\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "No run_configuration provided, running on local with default configuration\nRunning in the active local environment.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-02-16:22:58:19,981 INFO     [modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n2022-02-16:22:58:19,986 INFO     [modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n2022-02-16:22:58:23,577 INFO     [utils.py:159] NumExpr defaulting to 4 threads.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>az-capstone-automl</td><td>AutoML_71dd89a9-3ce2-4d06-9305-6dcae07d5526</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_71dd89a9-3ce2-4d06-9305-6dcae07d5526?wsid=/subscriptions/976ee174-3882-4721-b90a-b5fef6b72f24/resourcegroups/aml-quickstarts-186128/workspaces/quick-starts-ws-186128&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current status: DatasetEvaluation. Gathering dataset statistics.\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\nCurrent status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Class balancing detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       DONE\nDESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\nDETAILS:      \n+------------------------------+------------------------------+------------------------------+\n|Column name                   |Missing value count           |Imputation type               |\n+==============================+==============================+==============================+\n|MA4                           |1                             |mean                          |\n|MA50                          |1                             |mean                          |\n|MA80                          |1                             |mean                          |\n|btc                           |1                             |mean                          |\n|crude oil                     |2                             |mean                          |\n|difficulty                    |1                             |mean                          |\n|euro                          |1                             |mean                          |\n|ftse                          |1                             |mean                          |\n|gold                          |1                             |mean                          |\n|hashrate                      |1                             |mean                          |\n|high                          |1                             |mean                          |\n|hsi                           |1                             |mean                          |\n|low                           |1                             |mean                          |\n|nasdaq                        |1                             |mean                          |\n|nikkei                        |1                             |mean                          |\n|open                          |1                             |mean                          |\n|rates                         |1                             |mean                          |\n|shangai                       |1                             |mean                          |\n|silver                        |1                             |mean                          |\n|spy                           |1                             |mean                          |\n|std_dif                       |1                             |mean                          |\n|t_cost                        |1                             |mean                          |\n|vol_btc                       |1                             |mean                          |\n+------------------------------+------------------------------+------------------------------+\n\n********************************************************************************************\n\nTYPE:         High cardinality feature detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0   MaxAbsScaler LightGBM                          0:00:37             0.4935    0.4935\n    1   MaxAbsScaler XGBoostClassifier                 0:00:38             0.5050    0.5050\n    2   MaxAbsScaler ExtremeRandomTrees                0:00:29             0.4602    0.5050\n    3   SparseNormalizer XGBoostClassifier             0:00:32             0.5009    0.5050\n    4   StandardScalerWrapper KNN                      0:00:32             0.4724    0.5050\n    5   MaxAbsScaler LightGBM                          0:00:29             0.5072    0.5072\n    6   RobustScaler LogisticRegression                0:00:27             0.4776    0.5072\n    7   MaxAbsScaler LightGBM                          0:00:32             0.5009    0.5072\n    8   StandardScalerWrapper KNN                      0:00:34             0.4769    0.5072\n    9   StandardScalerWrapper SVM                      0:00:41             0.5131    0.5131\n   10   StandardScalerWrapper XGBoostClassifier        0:00:29             0.5061    0.5131\n   11   MinMaxScaler RandomForest                      0:00:34             0.4580    0.5131\n   12   StandardScalerWrapper LogisticRegression       0:00:28             0.5139    0.5139\n   13   StandardScalerWrapper KNN                      0:00:28             0.4969    0.5139\n   14   RobustScaler KNN                               0:00:31             0.4636    0.5139\n   15   MinMaxScaler KNN                               0:00:29             0.4739    0.5139\n   16   SparseNormalizer KNN                           0:00:27             0.4773    0.5139\n   17   MaxAbsScaler LogisticRegression                0:00:31             0.5116    0.5139\n   18   StandardScalerWrapper XGBoostClassifier        0:00:28             0.5120    0.5139\n   19   StandardScalerWrapper XGBoostClassifier        0:00:32             0.5098    0.5139\n   20   MaxAbsScaler LogisticRegression                0:00:26             0.5146    0.5146\n   21   StandardScalerWrapper XGBoostClassifier        0:00:30             0.4976    0.5146\n   22   StandardScalerWrapper XGBoostClassifier        0:00:32             0.5006    0.5146\n   23   SparseNormalizer XGBoostClassifier             0:00:30             0.5002    0.5146\n   24   RobustScaler ExtremeRandomTrees                0:00:29             0.4987    0.5146\n   25   MinMaxScaler LogisticRegression                0:00:28             0.4995    0.5146\n   26   MinMaxScaler LightGBM                          0:00:32             0.5065    0.5146\n   27   StandardScalerWrapper ExtremeRandomTrees       0:00:32             0.4980    0.5146\n   28   MaxAbsScaler LightGBM                          0:00:27             0.5006    0.5146\n   29   SparseNormalizer LightGBM                      0:00:27             0.5013    0.5146\n   30   "
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1644782458979
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "By using the RunDetails widget, we can appreciate different experiments metrics.\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance.\n",
        "Why do you think some models did better than others?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(automl_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644782459118
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save best model\n",
        "best_run, model = automl_run.get_output()\n",
        "print(best_run, '\\n')\n",
        "print(model)\n",
        "joblib.dump(value=best_run.id, filename=\"./models/bitcoin-automl.joblib\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644782460190
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models.\n",
        "Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'best-automl-model'\n",
        "description = \"AutoML model for predicting day-ahead Bitcoin price movements\"\n",
        "tags = None\n",
        "model = automl_run.register_model(model_name=model_name, description=description, tags=tags)\n",
        "print(automl_run.model_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461350
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644782461559
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "best_run.download_file('outputs/conda_env_v_1_0_0.yml', 'inference/conda_env.yml')\n",
        "best_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", \"inference/score.py\")\n",
        "best_run.download_file('outputs/model.pkl', 'inference/model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644784811730
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_file_name = \"./inference/score.py\"\n",
        "inference_config = InferenceConfig(environment=env, entry_script=script_file_name)\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=2,\n",
        "    memory_gb=2,\n",
        "    tags={\"area\": \"Trading\", \"type\": \"automl_classification\"},\n",
        "    description=\"service for Bitcoin trading signals\"\n",
        ")\n",
        "\n",
        "aci_service_name = model_name.lower()\n",
        "print(aci_service_name)\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)\n",
        "\n",
        "aci_service.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "X_test_json = df.tail().to_json(orient=\"records\")\n",
        "data = '{\"data\": ' + X_test_json + \"}\"\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
        "\n",
        "y_pred = json.loads(json.loads(resp.text))[\"result\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deletion of endpoints and resources"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the inference compute instance\n",
        "aci_service.delete()\n",
        "\n",
        "# Deleting compute cluster\n",
        "compute_target.delete()\n",
        "# print('Compute cluster deleted!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1645045473875
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}