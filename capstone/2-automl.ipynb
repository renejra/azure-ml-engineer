{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Automated ML\n",
    "\n",
    "Detailed package dependencies can be found on the [`env.yml`](envs/env.yml).\n",
    "Use `conda install --file envs/env.yml` on your Terminal.\n",
    "This file can be used to reproduce the conda environment used in this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.train.automl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/l4/4bv0qnl51_xdknpb_7gf8jc00000gn/T/ipykernel_5238/718035498.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mazureml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mWorkspace\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExperiment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEnvironment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDatastore\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mazureml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mComputeTarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAmlCompute\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mazureml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautoml\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAutoMLConfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mazureml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwidgets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mRunDetails\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'azureml.train.automl'"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import requests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # Setting up the workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Registering and building the environment (not needed in AutoML)\n",
    "env = Environment.from_conda_specification(name = \"az-capstone\", file_path = \"envs/env.yml\")\n",
    "env = env.register(workspace=ws)\n",
    "env_build = env.build(workspace=ws)\n",
    "\n",
    "# Setup the experiment\n",
    "exp_name = 'az-capstone-automl'\n",
    "exp=Experiment(ws, exp_name)\n",
    "\n",
    "# Enable logs\n",
    "run = exp.start_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now deploy the necessary Compute Cluster, or check if there is already an existing one we can use."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup the compute cluster\n",
    "compute_name = os.environ.get('CLUSTER_NAME', 'automl-cluster')\n",
    "compute_min_nodes = os.environ.get('CLUSTER_MIN_NODES', 0)\n",
    "compute_max_nodes = os.environ.get('CLUSTER_MAX_NODES', 4)\n",
    "vm_size = os.environ.get('CLUSTER_SKU', 'STANDARD_D2_V2')\n",
    "\n",
    "# Verify if the compute cluster exists\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=vm_size,\n",
    "        min_nodes=compute_min_nodes,\n",
    "        max_nodes=compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset we are using will be the one resulting from the [previous notebook](1-data-sourcing.ipynb) where\n",
    "we dug into data sourcing and did some processing prior this task. The dataset\n",
    "consists on financial data including OHLCV (open, high, low, close, volume) from diverse instruments (indices,\n",
    "commodities, interest rates...) and technical indicators (moving averages, RSI, standard deviation...), that we will\n",
    "use to create a ML-based trading model, that gives BUY, HOLD or SELL signals for Bitcoin trading.\n",
    "\n",
    "If you want to dig more into how the dataset looks like or\n",
    "into how the above-mentioned signals are generated, please refer to the \"labelling the data\" section of\n",
    "the [data sourcing notebook](1-data-sourcing.ipynb) or the latest  print view of the DataFrame's head and/or tail\n",
    "provided on the same file.\n",
    "\n",
    "The task we will be trying to solve is basically a **classification problem**.\n",
    "We are to predict whether the next-day, Bitcoin returns will be on the top 25% most positive returns (BUY, 1),\n",
    "the 25% most negative (SELL, -1), or somewhere in between (HOLD, 0).\n",
    "\n",
    "Since AutoML does grid search over features and normalization procedures, we will take joint, unaltered data as feed\n",
    "in to the model. What we will make is dropping the last features and labels that are not really needed for the task."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Access the data and drop unneeded columns for AutoML exercise\n",
    "df = pd.read_csv('data/df.csv')\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drop_col_list = ['', '']\n",
    "df.drop(columns=drop_col_list, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Register the dataset\n",
    "datastore = ws.get_default_datastore()\n",
    "dataset = Dataset.Tabular.register_pandas_dataframe(df, datastore, \"automl_dataset\", show_progress=True)\n",
    "df = dataset.to_pandas_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "Our AutoML run will have the classification task of predicting next day's buy, sell or hold label, or the column\n",
    "`y_c_weighted`. Our primary metric will be AUC weighted, to deal with the instability on price dataset.\n",
    " I'm also adding the automatic featurization, so\n",
    "AutoML takes care of necessary data transformations, trying out different methods.\n",
    "\n",
    "As timeout for this project I will use 30 minutes. The usage of VMs to access Azure on a limited time (1h) adds pressure\n",
    "on this metric. We also need time to analize results afterwards, so air time using the VM is important."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_settings = {\n",
    "    'featurization':'auto'\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set parameters for AutoMLConfig\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='AUC_weighted',\n",
    "    training_data=df,\n",
    "    label_column_name='y_c_shifted',\n",
    "    n_cross_validations=5\n",
    "    **automl_settings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Submit the experiment run\n",
    "automl_run = exp.submit(automl_config, show_output=False)\n",
    "automl_run.wait_for_completion(show_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Details\n",
    "\n",
    "By using the RunDetails widget, we can appreciate different experiments metrics.\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance.\n",
    "Why do you think some models did better than others?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrieve and save best automl model.\n",
    "aml_best_run, model = automl_run.get_output()\n",
    "print(aml_best_run)\n",
    "print(model)\n",
    "joblib.dump(value=aml_best_run.id, filename=\"./models/bitcoin-automl.joblib\")"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models.\n",
    "Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_name = automl_run.properties['model_name']\n",
    "description = \"AutoML model for predicting day-ahead Bitcoin price movements\"\n",
    "tags = None\n",
    "model = remote_run.register_model(model_name=model_name, description=description, tags=tags)\n",
    "print(remote_run.model_id)\n",
    "\n",
    "# TODO: CHECK IF WE NEED THESE LINES\n",
    "script_file_name = \"inference/score.py\"\n",
    "best_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", \"inference/score.py\")\n",
    "\n",
    "# Check what is this inference script\n",
    "inference_config = InferenceConfig(entry_script=script_file_name)\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=2,\n",
    "    tags={\"area\": \"Trading\", \"type\": \"automl_classification\"},\n",
    "    description=\"service for Bitcoin trading signals\",\n",
    ")\n",
    "\n",
    "aci_service_name = model_name.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)\n",
    "\n",
    "# aci_service.get_logs()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test_json = X_test.to_json(orient=\"records\")\n",
    "data = '{\"data\": ' + X_test_json + \"}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
    "\n",
    "y_pred = json.loads(json.loads(resp.text))[\"result\"]"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deletion of endpoints and resources"
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Deleting the inference compute instance\n",
    "# aci_service.delete()\n",
    "\n",
    "# Deleting compute cluster\n",
    "# compute_target.delete()\n",
    "# print('Compute cluster deleted!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}